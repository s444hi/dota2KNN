import numpy as np # fast arrays, math operations, manipulating arrays
import matplotlib.pyplot as plt # main plotting library, used for histograms, scatter plots, subplots
import pandas as pd # handles tabular data, loads csv into dataframe and grab feature/label columns
from sklearn.preprocessing import StandardScaler # scales fts to mean 0, variance 1
from sklearn.neighbors import KNeighborsClassifier, NearestCentroid # distance based classifiers
from sklearn.model_selection import train_test_split # splits data to training and testing
from sklearn.inspection import DecisionBoundaryDisplay # helps visualize classifier boundaries
from sklearn.metrics import accuracy_score # how well predictions match true labels

from google.colab import drive
drive.mount('/content/drive')

url = 'https://docs.google.com/spreadsheets/d/1GT0vNzFgCKWwnXHrz3ruC71f8W2qWxJ7nLNMGsfQlMY/export?format=csv'
df = pd.read_csv(url)

# mount to gd to access files, pandas downloads sheet --> exported as csv to dataframe df

df.head()

X = df.iloc[:, :-1]
y = df.iloc[:, -1].astype(int)

# pandas indexing iloc slices df my row/column, x = win rate, pick rate, kda, y = hero label (abaddon, wraith king, warlock)

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# converts features so they're ont the same scale because if it doesn't then knn and nc
# would be skwed

fig, axes = plt.subplots(1, 4, figsize=(12, 3))

for i in range(4):
  axes[i].hist(df.iloc[:,i], color='navy')
  axes[i].set_title(f"feature {i}")

  fig.tight_layout()

  # matplotlib makes histograms of first 4 features to check distributions
  # ft 0 = win rate, ft 1 = pick rate, ft 2 = kda, ft 3 = game mode

fig, axes = plt.subplots(4,4,figsize=(8,8))

for i in range(4):
    for j in range(4):
        axes[i, j].set_xlabel(f"feature {i}")
        axes[i, j].set_ylabel(f"feature {j}")

        if j == i:
            axes[i, j].hist(df.iloc[:, i], color='navy')
        else:
            for k in range(len(df)):
                if df.iloc[k]['Hero'] == 1:
                    axes[i, j].scatter(df.iloc[k, j], df.iloc[k, i], color='maroon', s=10)
                elif df.iloc[k]['Hero'] == 2:
                    axes[i, j].scatter(df.iloc[k, j], df.iloc[k, i], color='navy', s=10)
                else:
                    axes[i, j].scatter(df.iloc[k, j], df.iloc[k, i], color='orange', s=10)

fig.tight_layout()

# matplotlib creates 4x4 grid of plots, diagonal = histograms, rest = scatter of one ft vs another colored by class
# red: abaddon, blue: wraith king, yellow: warlock

# we can see that the red is highest for all the fts


seed = 1234
# random seed fixes the sequence of randon nums so that the experiment is reproducible
# so if i were to run this again i'll get the same train/test split instead of a new one every time
np.random.seed(seed) # tells numpy to use the chosen seed whenever there's randomness like shuffling
# without this results could vary run to run
Xtr, Xte, Ytr, Yte = train_test_split(X_scaled, y, test_size=0.3, random_state=seed, shuffle=True)
# breaks dataset into training data (for learnign) and test data (for evaluation)

# xscaled = fts (win rate, pick rate, kda, game mode)
# y = labels (abaddon, wraith king, warlock
# shuffle = true shuffles the rwos before splitting so the data isn't grouped by order

# Xtr: training features, Xte: testing features, Ytr: training labels, Yte: testing labels
# so the classifier is trained on xtr ytr and tested on xte, yte

# nc is a prototype classifier
# for each class, heros, find the centroid/mean vector of its training points after scaling
# to find a new point you compute the distance to each centroud (euclidian) and choose the closest one
NC = NearestCentroid() # construct model with defaults
NC.fit(Xtr, Ytr) # groups training rows by class/heor, computes class centroid with 4 fts, stores 3 centroids

Pred_tr = NC.predict(Xtr) # predict: for each row, compute distance to those 3 centroids then choose nearest
Pred_te = NC.predict(Xte)
Accuracy_tr = accuracy_score(Ytr, Pred_tr) # freaction correct
Accuracy_te = accuracy_score(Yte, Pred_te)

print(f"-- accuracy (train): {Accuracy_tr}")
print(f"-- accuracy (test): {Accuracy_te}")




from sklearn.neighbors import NearestCentroid
from sklearn.inspection import DecisionBoundaryDisplay
import matplotlib.pyplot as plt
import numpy as np

# yellow, warlock , teal, wraith king , purple, abaddon

X2_tr = Xtr[:, [0, 1]]
X2_te = Xte[:, [0, 1]]

nc2 = NearestCentroid()
nc2.fit(X2_tr, Ytr)

fig, ax = plt.subplots(figsize=(6,6))
DecisionBoundaryDisplay.from_estimator(nc2, X2_tr, response_method="predict", plot_method="pcolormesh", grid_resolution=300, alpha=0.5, cmap="viridis", ax=ax)

ax.scatter(X2_tr[:,0], X2_tr[:,1], c=Ytr, s=20, edgecolor="k")

centroids = nc2.centroids_
ax.scatter(centroids[:,0], centroids[:,1], marker="X", s=200, c=np.unique(Ytr), edgecolor = "k", linewidths=1)

ax.set_xlabel("Feature 0 (scaled)")
ax.set_ylabel("Feature 1 (scaled)")
ax.set_title("Nearest Centroid decision boundary with 2 ft")
plt.show()
